+++

date = "2019-10-17"
title = "数据挖掘比赛总结（10.17）"
tags = ["思考"]


+++

&nbsp; &nbsp; &nbsp; &nbsp;从七月份到九月底，主要参加了三个比赛：（1）安泰杯——跨境电商智能算法大赛；（2）全球数据智能大赛——广西水稻预测；（3）IEEE-CIS Fraud Detection。虽然最终的成绩都不是很好，但这几个比赛有值的总结的地方。

<!--more-->


#### 1. 安泰杯——跨境电商智能算法大赛（初赛：41/1960；复赛：36/1960）

&nbsp; &nbsp; &nbsp; &nbsp;这个比赛算是我参加的第一个数据挖掘的比赛，也花费了许多的时间和精力。虽然没能获奖，但收获还是颇丰的。该比赛是一个推荐类的比赛，数据量相对比较大。刚开始时，由于没有学习过推荐类的算法，对于那么多数据无从下手，用了最简单粗暴的数据处理方式，然后基于数据处理的结果使用逻辑回归做分类推荐，结果算法跑了很久都没有输出。之后就开始读相关的文献和书籍，一边学习一边实践。在初赛时，主要使用了基于用户的协同过滤和基于商品的协同过滤算法，虽然这两个算法比较简单，但如果不做数据的简化，我所使用的机器仍无法跑起来（内存不够）。最终基于商品的协同过滤算法可以实现0.09的得分。

&nbsp; &nbsp; &nbsp; &nbsp;在初赛的中期，一位大佬开源了一个简单的baseline：主要思想是推荐用户最近购买的商品。该baseline的得分是0.1568，榜单前一百也都成了0.1568+，而我也被挤出来前100。而后，只能基于该baseline进行提升，原因是要进复赛需要取得前100。经过无数次的尝试后，终于基于用户最近购买商品、商品的类别信息、热门商品购买信息通过一些规则的方式突破了baseline，也将初赛的得分定格在了0.1582(41名)。

&nbsp; &nbsp; &nbsp; &nbsp;在复赛的时候，由于复购率更高，因此一开始就采取了与初赛类似的方式，得分为0.5878。之后尝试通过商品类别Embedding的方式（DeepWalk算法）提分，结果并没有提高。加之当时的时间原因（有其他事件），导致放弃了继续进行探索，最终复赛的名次为36名。



#### 2. 全球数据智能大赛——广西水稻预测（初赛：32/719；复赛：48/719）

&nbsp; &nbsp; &nbsp; &nbsp;这个比赛一开始并没有打算投入时间和精力去做，只是看到该比赛的数据量较少，不需要太多的内存就可以使用各种模型。因此在初赛出榜的前一天随意做了EDA，然后用LightGBM进行预测。没想到第二天出分，竟是榜首，接下来的几天里，尝试了各种模型以及完善EDA，分数也有些许的提高，也一直处于榜首的位置。但是随着时间的增加，越来越多的大佬开始动手，我的名次也从榜首慢慢跌出了首页。由于一直没有好的线下和线上一致的验证方式，导致每次线下分数的提高都不能保证线上的得分。

&nbsp; &nbsp; &nbsp; &nbsp;另外这个比赛的复赛只有一次测评机会，并且初赛和复赛预测的数据分布并不一定相同，导致比赛具有很大的随机性。复赛结果的提交，我选择了与初赛最好成绩相同的模型进行预测，最终的结果并不好（初赛：32/719；复赛：48/719）。

&nbsp; &nbsp; &nbsp; &nbsp;关于这比赛有一个trick，是复赛结束时在比赛群里看到的：在复赛预测的数据中有一年的标签是个很强的噪点（某个县的2017年产量晚稻的产量由于降水等因素导致非常低）。若发现使用这个trick，复赛的模型会比较好一些。但是这个trick是我没有发现的，原因是自己没有做好EDA，也没有相关比赛的经验。

#### 3. IEEE-CIS Fraud Detection（Private Leaderboard：2147/6381）

&nbsp; &nbsp; &nbsp; &nbsp;这个比赛是从一个Kaggle竞赛相关的公众号上得知的，上面有关于该比赛的基本的一些EDA方法。对于该比赛，一开始采用了自己的EDA方式，做了一些简单的数据的编码、去噪、填充等操作，然后使用LightGBM进行分类预测，最终线上的AUC大约为0.90，这距离别人的分数还有很大的差距。之后，就尝试了别人的EDA方式以及模型的参数，分数确实提升了不少，但距离前排还有很大差距。由于时间的问题，没有进一步跟进，只是尝试融合别人的结果。虽然public score不断提分，但是最终的private score分数掉了很多。

&nbsp; &nbsp; &nbsp; &nbsp;比赛结束后，看到前排关于自己方法的总结中，有一个关于Magic Feature：他们团队使用了一个一般都会丢弃的UID，从而使得他们的模型非常好。



#### 总结

关于这几次数据挖掘比赛，我认为比较重要的几个方面是：（1）EDA很重要，通常使用的模型都是相同的，参数的调整也是有限的，而不同的EDA往往会使得结果出现很大的波动；（2）对于训练集数据，要进行数据分析，剔除一些影响训练模型的离群点（噪声点），方法是进行十折交叉验证，挑出结果较差的某一折，分析验证集数据；（3）对于时间跨度较长的比赛，要能够坚持，即使大佬众多，提分无望，也要尝试不断提分。
