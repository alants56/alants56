---

date : 2019-03-19
title : 极大似然估计与贝叶斯估计
tags : ["machine learning"]
author : "月光晒谷"

---




&nbsp; &nbsp; &nbsp; &nbsp;通过贝叶斯等方式实现分类器时，需要首先得到先验概率以及类条件概率密度。但在实际的应用中，先验概率与类条件概率密度并不能直接获得，它们都需要通过估计的方式来求得一个近似解。若先验概率的分布形式已知（或可以假设为某个分布），但分布的参数未知，则可以通过极大似然或者贝叶斯来获得对于参数的估计。

<!--more-->

&nbsp; &nbsp; &nbsp; &nbsp;极大似然估计的主要思想是：把待估计的参数看为确定的量，只是取值未知，其最佳估计是使得产生已知样本的概率值最大时的参数取值。贝叶斯估计的主要思想是：把待估计的参数看成是符合某种先验概率分布的随机变量，对样本进行观测的过程就是把先验概率转化为后验概率密度的过程，这样通过现有的样本信息修正对于参数的估计值。


&nbsp; &nbsp; &nbsp; &nbsp;接下来通过一个实例来阐述极大似然估计和贝叶斯估计。设样本为$T=\\{(x\_1,y\_1),$ $(x\_2,y\_2),..., $ $(x\_N,y\_N)\\}$，其中$x\_i \in R$，$y\_i \in \\{+1, -1\\}$，$i=1,2,...,N$。使用贝叶斯作为分类器，则需要求如下后验概率：

$$P(y^{(k)}|x)= \frac {p(x|y^{(k)})P(y^{(k)})}{\sum\_{j} p(x|y^{(j)})P(y^{(j)})} \quad $$

注：$P(y^{(k)})$表示$P(y=y^{(k)})$的概率，$y^{(k)}$表示具体分类，可以为$+1$或$-1$，$p(x)$表示$x$点的概率密度


要求解上式的后验概率$P(y^{(k)}|x)$则需要先求类条件概率密度$p(x|y^{(k)})$。若预先知道$p(x|y^{(k)})$ $ \sim $ $ N(\mu ,\sigma^{2}\_{0} )$（或假设其服从某个分布，参数未知），并且仅有参数$\mu$未知（两个参数都未知的情况类似）。

&nbsp; &nbsp; &nbsp; &nbsp;若使用__极大似然估计__，设$\mu$为一个确定的量，它的最佳估计值是使得出现样本情况时的最大概率时的取值。最大概率用一个如下的似然函数来表示：

$$L(\mu) = \prod \_{i=1} ^{n} p(x\_i|y^{(k)})\quad $$

其中上式中$n$表示标签为$y^{(k)}$的样本数，$x\_i$表示标签为$y^{(k)}$时的样本。我们要求上式最大时参数$\mu$的取值，由于上式为多项相乘，可以请先取对数，然后求极值。

$$ln L(\mu) = \sum \_{i=1} ^{n} ln p(x\_i|y^{(k)})= \sum \_{i=1} ^{n}[-ln \sqrt{2\pi}\sigma\_{0}-\frac{(x\_i - \mu)^{2}}{2\sigma^{2}\_{0}}]$$

由于上式为凸函数，可以通过求导，并令导数为0得到极值点。因此有如下等式：

$$\frac{\partial lnL(\mu)}{\partial \mu}=- \frac{1}{\sigma^{2}\_{0}} \sum\_{i=1}^{n}(x\_i - \mu) = \frac{1}{\sigma^{2}\_{0}}(n\mu-\sum\_{i=1}^{n}x\_i) = \frac{1}{\sigma^{2}\_{0}}(n\mu-n\overline{x}^{(k)})=0$$

最终得到$\mu$的最佳估计值为$\hat \mu = \overline{x}^{(k)}$，由此可以得到类条件概率密度函数$p(x|y^{(k)})$ $ \sim $ $ N( \overline{x}^{(k)},\sigma^{2}\_{0} )$。


&nbsp; &nbsp; &nbsp; &nbsp;若使用__贝叶斯估计__，设$\mu$为一个随机变量，则$p(x|\mu)$ $\sim$ $N(\mu,\sigma\_{0}^{2})$，它的概率密度函数已知（或假设其服从某个已知分布）：$p(\mu)$ $\sim$ $N(\mu \_{1}, \sigma \_{1} ^{2})$，其中$\mu \_{1}$与$ \sigma \_{1}^{2}$为已知量。。由贝叶斯公式可以由如下等式：


$$p(\mu|(x\_1,x\_2,...,x\_n))= \frac{p((x\_1,x\_2,...,x\_n)|\mu)p(\mu)}{\int p((x\_1,x\_2,...,x\_n)|\mu)p(\mu)du}$$


其中上式中$x\_1,x\_2,...,x\_n$表示标签为$y^{(k)}$时的样本，上式的分母为一个不依赖于参数的值，可将其计为$\lambda$，由于样本是独立同分布，则可将概率密度函数带入得到如下等式：

$$
\begin{align}
p(\mu|(x\_1,x\_2,...,x\_n)) 
&= \lambda p((x\_1,x\_2,...,x\_n)|\mu)p(\mu) \\\\\\\\
&= \lambda \prod \_{i=1} ^{n}p(x\_{i}|\mu)p(\mu) \\\\\\\\
&=\lambda' exp(-\frac{1}{2}((\frac{n}{\sigma\_{0} ^{2}} + \frac{1}{\sigma\_{1} ^{2}}) \mu ^{2}- 2(\frac{1}{\sigma\_{0} ^{2}} \sum \_{i=1} ^{n} x\_{i} + \frac{\mu\_{1}}{\sigma\_{1}^{2}})\mu ))
\end{align}
$$

由上式可知$p(\mu|(x\_1,x\_2,...,x\_n))$ 服从正态分布，设$p(\mu|(x\_1,x\_2,...,x\_n))$ $\sim$ $N(\mu\_{k} , \sigma\_{k}^{2})$，则：


$$
\begin{align}
p(\mu|(x\_1,x\_2,...,x\_n)) &= \frac{1}{\sqrt{(2 \pi)} \sigma\_{k}} exp (-\frac{(\mu - \mu_{k})^{2}}{2 \sigma\_{k} ^{2}}) \\\\\\\\
&= \lambda' exp(-\frac{1}{2} (\frac{1}{\sigma\_{k} ^{2}}\mu^{2} - 2\frac{\mu\_{k}}{\sigma\_{k} ^{2}}\mu))
\end{align}
$$


以上两个等式对应项相等可得：


$$\mu\_{k} = (\frac{n \sigma\_{1}^{2}}{n \sigma\_{1}^{2} + \sigma\_{0}^{2}}) \overline{x}^{(k)} + \frac{\sigma\_{0}^{2}}{n\sigma\_{1}^{2} + \sigma\_{0}^{2}}\mu\_{1}$$


$$\sigma\_{k}^{2} =  \frac{\sigma\_{1}^{2}\sigma\_{0}^{2}}{n\sigma\_{1}^{2} + \sigma\_{0}^{2}}$$


接下来我们可以通过如下等式求得类条件概率密度：

$$p(x|y^{(k)}) = \int p(x|\mu)p(\mu|(x\_1,x\_2,...,x\_n))d\mu$$

***

1.参考文档：

&nbsp; &nbsp; &nbsp; &nbsp;[1]. 模式分类&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Richard O.Duda 等著&nbsp; &nbsp; &nbsp; &nbsp;李宏东 等译
