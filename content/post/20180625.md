---

date : "2018-06-25"
title : "关于机器学习的一些杂谈"
tags : ["杂谈","思考"]


---

&nbsp; &nbsp; &nbsp; &nbsp;晚上睡不着，突然想了一些机器学习中的问题，发现似乎可以类比于生活。因为从某种程度来说，机器学习是模仿人类学习，那么反推回去，机器学习似乎也可以给生活或学习一些启示。

<!--more-->


&nbsp; &nbsp; &nbsp; &nbsp;机器学习中的损失函数，是用来衡量一个机器学习模型的好坏程度。通常机器学习的过程就是不断的使得损失函数减少的过程。对于生活与学习来说，就是我们对于一件事情的期望或者自己最终要实现的目标。我们最想做的就是不断的缩小与目标的差距，最终实现目标。


&nbsp; &nbsp; &nbsp; &nbsp;机器学习中模型参数的初值，一般是随机化赋值或用全零进行初始化。在机器学习过程中，好的初值可以减少机器学习迭代的次数；而不好的初值可能会导致最终无法达到全局最优解（当然也取决于你选择求解最优问题的算法）。比如，求解一个非凸问题的全局最优解，若我们使用梯度下降法求解，可能因为初值选择的位置不同，会得到局部最优解或者全局最优解。这就好比一个人在某些方面与生俱来的天赋，似乎并不需要过多的训练就可以比平常的人对于该方面做的要好。而有些人没有很好的天赋，经过了很长时间的训练也取得了很不错的成绩。当然还有一些人很努力但表现出的结果并不好，类比于机器学习中的初值问题，可能他们的天赋与方法并不是很好，只能到达局部的最优，无法实现自我的超越。


&nbsp; &nbsp; &nbsp; &nbsp;机器学习中的深度神经网络(DNN)，是通过简单的神经元进行多层次的相连所得到的。它是对人的神经网络的模拟，但又并非完全是模拟人的神经网络的处理过程。DNN看似很简单，但只要赋予它初值，然后不断的训练，总能得到一定的结果。而我看到有一些科学家做过一些实验（一般讲深度神经网络的课程似乎都会引用这些实验），通过不断的训练以及辅助一些传感器，让舌头可以辨别颜色。而对于一种技能（比如某种语言的学习），只要反复的训练，最终都能到达一定的熟练程度。这正如人们所熟知的一万小时定律。

&nbsp; &nbsp; &nbsp; &nbsp;过拟合，是机器学习中一个令人头疼的问题，它指的是机器学习中得到的模型在训练集上具有非常好的性能，但是在测试集上性能却很差。与之相对应的是欠拟合，它指的是在训练集和测试集上性能都很差。在生活中，每当出现一种新兴的事物，年轻人往往要比老年人接收的快些。大概是因为对于新事物相当于机器学习中的测试集，老年人的生活阅历已经很多了，他们可能会处于过拟合的状态。他们对于该事物的预期比该事物本身的结果要差很多，此时若他们不肯改变自己固有的一些思想，就会很难接新事物。相较于年轻人，他们则处于欠拟合的状态，但是由于预期与结果都不好，他们则更容易主动改变思想，从而接受新事物。


&nbsp; &nbsp; &nbsp; &nbsp;生活中，还有一种类似过拟合的情况，比如父母与子女，经常会意见不合。虽然子女继承了父母的基因，但这只是初值可能类似。但由于父母所成长的年代与子女的成长年代有很大的不同，即训练集不同。对于一件事情，可能就是因为父母的过拟合与子女的过拟合导致两代人之间的代沟。


&nbsp; &nbsp; &nbsp; &nbsp;那么，机器学习中的一些问题对我们生活有什么启示？通常，解决某一个机器学习的问题一般的步骤为：

>
* 模型选择
* 策略选择
* 算法实现
* 不断训练获取最优解


而我们做事的一般步骤也是如此：

> 
* 目标一致
* 方法恰当
* 持之以恒


&nbsp; &nbsp; &nbsp; &nbsp;还有，关于机器学习中的过拟合现象，一般改善的方法：增加训练集的数据或是正则化。增加训练集的数据，就是要让模型尽可能的考虑到更多的情况；而正则化，则是通过增加惩罚项，使得选择尽可能简单的模型，因为简单的模型往往具有更好的范性。而对于我们的生活和学习来说，为了避免“过拟合”的现象，我们应该学会去接纳一些“新兴”的事物，而不是固守自己的想法。另外，我们也可以尽可能的让自己的生活更简单些,或许就不会有那么多的不愉快了。正如Unix设计哲学中的KISS准则：“Keep it simple, stupid!”


&nbsp; &nbsp; &nbsp; &nbsp;当然，本文纯属个人想法，仅供参考。
