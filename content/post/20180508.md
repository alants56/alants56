+++

date = "2018-05-08"
title = "Logistic Regression"
tags = ["machine learning","logistic regression"]

+++

&nbsp; &nbsp; &nbsp;&nbsp;虽然logistic regression名为回归，但却是一个机器学习中的分类方法。我们先用它来处理二分类问题，基本模型如下，定义出了Y=1和Y=0的概率。

<!--more-->

![LogisticRegression0](http://liuao.tech/images/LogisticRegression0.png)



&nbsp; &nbsp; &nbsp;&nbsp;模型中的f(x)是一个名为sigmoid的函数，它的一个很重要特征是：当x小于0时，函数值小于0.5；当x大于0时，函数值大于0.5。将f(x)求导可以发现，其导数为f(x)(1-f(x))。

![LogisticRegression1](http://liuao.tech/images/LogisticRegression1.png)


&nbsp; &nbsp; &nbsp;&nbsp;考虑对于任意给定的数据集D，借用上述模型然后使用极大似然法估计，则似然函数L以及对数似然函数lnL如下所示：

![LogisticRegression2](http://liuao.tech/images/LogisticRegression2.png)



&nbsp; &nbsp; &nbsp;&nbsp;对于上述的未知参数w和b，我们可以使用梯度下降算法求其最优解。但要注意，所求是满足极大似然函数最大时的w和b，因此我们的损失函数可以定义为对数似然函数的相反数（这里的-lnL得到的结果被称为交叉损失熵），如下所示：


![LogisticRegression3](http://liuao.tech/images/LogisticRegression3.png)


&nbsp; &nbsp; &nbsp;&nbsp;上述考虑的是二分类问题，如果是多分类的问题，则可以定义如下模型，参数的确定类似于二分类问题，通过极大似然函数以及梯度下降算法求解。

![LogisticRegression4](http://liuao.tech/images/LogisticRegression4.png)



***

参考文档：

&nbsp; &nbsp; &nbsp; &nbsp;1. 统计学习方法&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;李航 著